{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion_MNIST_with_Keras_and_Deep_Learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rezwanh001/Fashion-MNIST-with-CNN/blob/master/Fashion_MNIST_with_Keras_and_Deep_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "qQb0rQLReLf0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4bnagxfIebqT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**The Fashion MNIST dataset is meant to be a (slightly more challenging) drop-in replacement for the (less challenging) MNIST dataset.**\n",
        "\n",
        "\n",
        "\n",
        "Similar to the MNIST digit dataset, the Fashion MNIST dataset includes:\n",
        "\n",
        "1.   60,000 training examples\n",
        "2.   10,000 testing examples\n",
        "3.   10 classes\n",
        "4.    28Ã—28 grayscale/single channel images\n",
        "\n",
        "\n",
        "The ten fashion class labels include:\n",
        "\n",
        "1.  T-shirt/top\n",
        "2.  Trouser/pants\n",
        "3.  Pullover shirt\n",
        "4.  Dress\n",
        "5.  Coat\n",
        "6.  Sandal\n",
        "7.  Shirt\n",
        "8.  Sneaker\n",
        "9.  Bag\n",
        "10. Ankle boot\n",
        "\n",
        "\n",
        "*References:*\n",
        "\n",
        "[1. Fashion MNIST with Keras and Deep Learning](https://www.pyimagesearch.com/2019/02/11/fashion-mnist-with-keras-and-deep-learning/)\n",
        "\n",
        "[2. fashion-mnist](https://github.com/zalandoresearch/fashion-mnist)\n",
        "\n",
        "[3. http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/)"
      ]
    },
    {
      "metadata": {
        "id": "YwUJvzjiyuCn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### (1) Download the Fashion MNIST dataset"
      ]
    },
    {
      "metadata": {
        "id": "oQG69BP1gRiY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d6b01ba2-e187-46b0-b0d5-60f93772d406"
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "WZHUMb3SzZNM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "f1aec199-e283-47d7-bcae-b0392306439d"
      },
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jCXRHvZ7zvor",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "55bc196b-4cfc-402e-e277-20b38560f1b1"
      },
      "cell_type": "code",
      "source": [
        "!tree --dirsfirst"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: tree: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vySJzt9x0WVP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### (2) Defining a simple Convolutional Neural Network (CNN)"
      ]
    },
    {
      "metadata": {
        "id": "SmKEHFTez-eU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
        "from keras import backend as K\n",
        "\n",
        "class CNN:\n",
        "  @staticmethod\n",
        "  def build(width, height, depth, classes):\n",
        "    # initialize the model along with the input shape\n",
        "    # to be \"channels last\" and the channels dimension itself\n",
        "    model = Sequential()\n",
        "    inputShape = (height, width, depth)\n",
        "    chanDim = -1\n",
        "    \n",
        "    # if we are using \"channels first\", update the input shape\n",
        "    # and channels dimension\n",
        "    if K.image_data_format() == \"channels_first\":\n",
        "      inputShape = (height, width, depth)\n",
        "      chanDim = 1\n",
        "      \n",
        "    # 1st CONV -> RELU -> CONV -> RELU -> POOL layer set\n",
        "    model.add(Conv2D(32, (3,3), padding='same', input_shape=inputShape))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization(axis=chanDim))\n",
        "    model.add(Conv2D(32, (3,3), padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization(axis=chanDim))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        "    \n",
        "    # 2nd CONV -> RELU -> CONV -> RELU -> POOL layer set\n",
        "    model.add(Conv2D(64, (3,3), padding='same', input_shape=inputShape))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization(axis=chanDim))\n",
        "    model.add(Conv2D(64, (3,3), padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization(axis=chanDim))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        "    \n",
        "    # 1st (and only) set of FC => RELU layers\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.25))\n",
        "    \n",
        "    # softmax classifier\n",
        "    model.add(Dense(classes))\n",
        "    model.add(Activation(\"softmax\"))\n",
        "    \n",
        "    # return the constructed network architecture\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IiVlpzug-zOv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Pooling layers help to progressively reduce the spatial dimensions of the input volume.\n",
        "*  Batch normalization, as the name suggests, seeks to normalize the activations of a given input volume before passing it into the next layer. It has been shown to be effective at reducing the number of epochs required to train a CNN at the expense of an increase in per-epoch time.\n",
        "*  Dropout is a form of regularization that aims to prevent overfitting. Random connections are dropped to ensure that no single node in the network is responsible for activating when presented with a given pattern.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "3eTl48hUDD6S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### (3) Implementing the Fashion MNIST training script with Keras"
      ]
    },
    {
      "metadata": {
        "id": "U5Yyh0wgDMVS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now that CNN is implemented we can move on to the driver script which:\n",
        "\n",
        "* Loads the Fashion MNIST dataset.\n",
        "* Trains CNN on Fashion MNIST + generates a training history plot.\n",
        "* Evaluates the resulting model and outputs a classification report.\n",
        "* Creates a montage visualization allowing us to see our results visually."
      ]
    },
    {
      "metadata": {
        "id": "M4ExD77C-ySX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "e382ca57-688f-4d75-aa33-8512ad700eac"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.use(\"Agg\") #The \"Agg\"  backend is used for Matplotlib so that we can save our training plot to disk.\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.optimizers import SGD, Adam, Adadelta\n",
        "from keras.utils import np_utils\n",
        "from imutils import build_montages\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# Initialize EPOCHS, LR_RATE, BATCH_SIZE\n",
        "NUM_EPOCHS = 5\n",
        "INIT_LR = 1e-2\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "## if we are using \"channels_first\" ordering, then reshape the design\n",
        "## matrix such that the matrix is:\n",
        "## num_sanples x depth x rows x cols\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "  X_train = X_train.reshape((X_train.shape[0], 1 , 28, 28))\n",
        "  X_test = X_test.reshape((X_test.shape[0], 1 , 28, 28))  \n",
        "else:\n",
        "  ## Otherwise use \"channels_last\"\n",
        "  X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))\n",
        "  X_test = X_test.reshape((X_test.shape[0], 28, 28, 1)) \n",
        "  \n",
        "\n",
        "  \n",
        "## Preprocess dataset + prepare data\n",
        "\n",
        "# Scale data to the frame of [0, 1]\n",
        "X_train = X_train.astype(\"float32\") / 255.0\n",
        "X_test = X_test.astype(\"float32\") / 255.0\n",
        "\n",
        "#one=hot encode the training and test labels\n",
        "y_train = np_utils.to_categorical(y_train, 10)\n",
        "y_test = np_utils.to_categorical(y_test, 10)\n",
        "\n",
        "# initialize the labels names\n",
        "labelNames = [\"top\", \"trouser\", \"pullover\", \"dress\", \"coat\",\n",
        "\t\"sandal\", \"shirt\", \"sneaker\", \"bag\", \"ankle boot\"]\n",
        "\n",
        "# Initialize the optimizer and model\n",
        "print(\"Copiling Model...\")\n",
        "opt = SGD(lr=INIT_LR, momentum=0.9, decay=INIT_LR / NUM_EPOCHS)\n",
        "model = CNN.build(width=28, height=28, depth=1, classes=10)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, \n",
        "                                   metrics=['accuracy'])\n",
        "\n",
        "# Train The model\n",
        "print(\"Training model...\")\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
        "                   batch_size=BATCH_SIZE, epochs=NUM_EPOCHS)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copiling Model...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Training model...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 32s 532us/step - loss: 0.4416 - acc: 0.8436 - val_loss: 0.3090 - val_acc: 0.8897\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 29s 491us/step - loss: 0.3052 - acc: 0.8891 - val_loss: 0.2694 - val_acc: 0.9050\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 29s 491us/step - loss: 0.2775 - acc: 0.8969 - val_loss: 0.2554 - val_acc: 0.9082\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 30s 492us/step - loss: 0.2602 - acc: 0.9046 - val_loss: 0.2350 - val_acc: 0.9162\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 30s 492us/step - loss: 0.2512 - acc: 0.9095 - val_loss: 0.2461 - val_acc: 0.9117\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cb_75xGXkzLH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        },
        "outputId": "27bc10ac-e20e-4dfe-d506-e5ba05478ba1"
      },
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 28, 28, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 28, 28, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 14, 14, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               1606144   \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,679,082\n",
            "Trainable params: 1,677,674\n",
            "Non-trainable params: 1,408\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "voc_v19jVwZ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "1f36489d-cce2-4e35-f65c-f762f299ce14"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "POuPnt8UE0Y8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "e0aff52f-52d4-4fa5-ec3a-a7a18bc7192c"
      },
      "cell_type": "code",
      "source": [
        "### Save model\n",
        "###==========================================\n",
        "from keras.models import load_model \n",
        "model.save('/content/gdrive/My Drive/Fashion_MNIST/fashion_mnist_cnn_model.h5') # creates a HDF5 file 'my_model.h5' \n",
        "\n",
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_train, y_train, verbose=1)\n",
        "print(\"Train Score: %.2f%%\" % (scores[0]*100))\n",
        "print(\"Train Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "############## Final evaluation of the model For Test Set\n",
        "score = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(\"Test Score: %.2f%%\" % (score[0]*100))\n",
        "print(\"Test Accuracy: %.2f%%\" % (score[1]*100))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 8s 130us/step\n",
            "Train Score: 20.54%\n",
            "Train Accuracy: 92.41%\n",
            "10000/10000 [==============================] - 1s 129us/step\n",
            "Test Score: 24.61%\n",
            "Test Accuracy: 91.17%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xcr3L49vyhlT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "0ecf086b-446c-49e6-cc94-8a1c7668fa93"
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model \n",
        "#### Load Save nodel\n",
        "# returns a compiled model \n",
        "# identical to the previous one \n",
        "mmodel = load_model('/content/gdrive/My Drive/Fashion_MNIST/fashion_mnist_cnn_model.h5')\n",
        "scores = mmodel.evaluate(X_train, y_train, verbose=1)\n",
        "print(\"Train Score Again: %.2f%%\" % (scores[0]*100))\n",
        "print(\"Train Accuracy Again: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "############## For Test Set from loading models\n",
        "score = mmodel.evaluate(X_test, y_test, verbose=1)\n",
        "print(\"Test Score Again: %.2f%%\" % (score[0]*100))\n",
        "print(\"Test Accuracy Again: %.2f%%\" % (score[1]*100))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 9s 149us/step\n",
            "Train Score Again: 20.54%\n",
            "Train Accuracy Again: 92.41%\n",
            "10000/10000 [==============================] - 1s 143us/step\n",
            "Test Score Again: 24.61%\n",
            "Test Accuracy Again: 91.17%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nDGHmtrB265B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "60000/60000 [==============================] - 9s 150us/step\n",
        "* Train Score : 6.41%\n",
        "* Train Accuracy : 97.81%\n",
        "\n",
        "10000/10000 [==============================] - 1s 142us/step\n",
        "* Test Score : 17.88%\n",
        "* Test Accuracy : 94.03%"
      ]
    },
    {
      "metadata": {
        "id": "D_w7uB9GEYQW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Predict on the test set(X_test)"
      ]
    },
    {
      "metadata": {
        "id": "jTXNEmeLERdO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "7e8ebd26-c513-4a3c-8c56-a6679f0e48f1"
      },
      "cell_type": "code",
      "source": [
        "# make predictions\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "# show the nicely formatted classification report\n",
        "print(\"Evaluating network...\")\n",
        "print(classification_report(y_test.argmax(axis=1), preds.argmax(axis=1),\n",
        "     target_names=labelNames))\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         top       0.90      0.83      0.86      1000\n",
            "     trouser       1.00      0.98      0.99      1000\n",
            "    pullover       0.92      0.80      0.86      1000\n",
            "       dress       0.89      0.93      0.91      1000\n",
            "        coat       0.82      0.90      0.86      1000\n",
            "      sandal       0.99      0.98      0.99      1000\n",
            "       shirt       0.72      0.79      0.75      1000\n",
            "     sneaker       0.94      0.99      0.96      1000\n",
            "         bag       0.98      0.98      0.98      1000\n",
            "  ankle boot       0.98      0.95      0.97      1000\n",
            "\n",
            "   micro avg       0.91      0.91      0.91     10000\n",
            "   macro avg       0.91      0.91      0.91     10000\n",
            "weighted avg       0.91      0.91      0.91     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JV3IjN6Uk7fx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fa1b1f92-7d14-4e1b-9cde-0cbf45a39ec3"
      },
      "cell_type": "code",
      "source": [
        "### List all data in history\n",
        "print(history.history.keys())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uiHdjyVAWV9f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#plot the training loss and accuray\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, NUM_EPOCHS), history.history['loss'], label='train_loss')\n",
        "plt.plot(np.arange(0, NUM_EPOCHS), history.history['val_loss'], label='val_loss')\n",
        "plt.plot(np.arange(0, NUM_EPOCHS), history.history['acc'], label='train_acc')\n",
        "plt.plot(np.arange(0, NUM_EPOCHS), history.history['val_acc'], label='val_acc')\n",
        "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "# plt.legend(loc=\"lower left\")\n",
        "# # plt.savefig(\"plot_perf.png\")\n",
        "plt.legend(loc = 'upper left')\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"/content/gdrive/My Drive/Fashion_MNIST/plot_loss_acc.png\", dpi = 50)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JABwpVIbqgoU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Initialize our list of output images\n",
        "images = []\n",
        "\n",
        "# randomly select a few testing fashion items\n",
        "for i in np.random.choice(np.arange(0, len(y_test)), size=(16,)):\n",
        "  # classify the clothing\n",
        "  probs = model.predict(X_test[np.newaxis, i])\n",
        "  prediction = probs.argmax(axis=1)\n",
        "  label = labelNames[prediction[0]]\n",
        "  \n",
        "  # extract the image from the test data if using \"channel_first\" ordering\n",
        "  if K.image_data_format() == \"channels_first\":\n",
        "    image = (X_test[i][0] * 255).astype(\"uint8\")\n",
        "    \n",
        "  # otherwise \"channels_last\"\n",
        "  else:\n",
        "    image = (X_test[i] * 255).astype(\"uint8\")\n",
        "    \n",
        "  # initialize the text label color as green(correct)  \n",
        "  color = (0, 255, 0)\n",
        "  \n",
        "  # otherwise, the class label prediction is incorrect\n",
        "  if prediction[0] != np.argmax(y_test[i]):\n",
        "    color = (0, 255, 0)\n",
        "    \n",
        "  # merge the channels into one image and resize the image from\n",
        "  # 28 x 28 to 96 x 96 so we can better see it and draw the \n",
        "  # predicted label on the image\n",
        "  image = cv2.merge([image] * 3)\n",
        "  image = cv2.resize(image, (96, 96), interpolation=cv2.INTER_LINEAR)\n",
        "  cv2.putText(image, label, (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.75,\n",
        "             (0, 255, 0), 2)\n",
        "  \n",
        "  # add the image to our list of output images\n",
        "  images.append(image)\n",
        "  \n",
        "# construct the montage for images\n",
        "montage = build_montages(images, (96, 96), (4, 4))[0]\n",
        "\n",
        "# show the output montage\n",
        "cv2.imshow(\"Fashion MNIST\", montage)\n",
        "cv2.waitKey(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6u3Yv1eax_Li",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}